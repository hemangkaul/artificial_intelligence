Supervised Learning
-given a data set of input output pairs, learn a function to map inputs to outputs

Classification
-supervised learning task of learning a function mapping an input point to a discrete category

f(humidity,pressure) = Rain or no Rain

hypothesis function, h(humidity, pressure)

nearest neighbor classification
-algorithm that, given an input, chooses the class of the nearest data point to that input

k-nearest neighbor classification
--algorithm that, given an input, chooses the most common class out of the k nearest data points to that input


x1 = Humidity
x2 = pressure
h(x1, x2) = Rain (1) if w0 + w1x1 + w2x2 >= 0
            No Rain (0) otherwise

Weight vector W: (w0, w1, w2)
Input vector x: (1, x1, x2)
w . x: w0 + w1x1 + w2x2

hw(x) = 1 if w . x >= 0
        0 otherwise

perceptron learning rule
-given data point (x,y) update each weight according to:
wi = wi + alpha(y - hw(x)) * xi

hard threshold vs soft threshold

Support vector machines
-maxmium margin seperator
    - some boundary that maximizes the distance between any of the data points

regression
-supervised learning task of learning a function mapping an input point to a continuous value

f(advertising)
    f(1200) = 5800
    f(2800) = 13400
    f(1800) = 8400
h(advertising)

Evaluating hypotheses
loss function
    - function that expresses how poorly our hypothesis performs

0-1 Loss function
L(actual, predicted) =
    0 if actual = predicted
    1 otherwise

L1 loss function
    L(actual, predicted) = |actual - predicted|

L2 loss function
    L(actual, predicted) = (actual - predicted)^2

overfitting
a model that fits too closely to a particular data set and therefore may fail to generalize to future data

cost(h) = loss(h) + lambda * complexity(h)
^regularization^
-penalizing hypotheses that are more complex to favor simpler, more general hypotheses

holdout cross-validation
splitting data into a training set and a test set, such that learning happens on the training set and is evaluated on the test set

kfold cross-validation
splitting data into k sets and experimenting k times, using each set as a test set once, and using remaining data as training set

scikit-learn (see src 4)

Reinforcement Learning
-given a set of rewards or punishments, learn what actions to take in the future

Markov decision process
=model for decision making, representing states, actions, and their rewards
set of states S
set of actions ACTIONS(s)
transition model P(s'|s,a)
reward function R(s, a, s')

Q-learning
method for learning a function Q(s,a) estimate of the value of performing an action a in state s

start with Q(s,a) = 0 for all s,a
when we take an action a recieve a reward:
    estimate the value of Q(s,a) based on current reward and expected future rewards
    update Q(s,a) to take into account old estimate as well as our new estimate

start with Q(s,a) = 0 for all s,a
every time we take an action a in state s and observe a reward r, we update:
    Q(s,a) <- Q(s,a) + alpha(r + lambda*max<actions> Q(s',a') (new value estimate) - Q(s,a) (old value estimate))

Greedy Decision-making
- when in state s, choose action a with highest Q(s,a)

Explore vs Exploit

Epsilon Greedy
set epsilson equal to how often we want to move randomly
with probability 1-epsilon, choose estimated best move
with probability epsilon choose a random move

function approximation
approximating Q(s,a) often by a function comibining various features rather than storing one value for every state-action pair

Unsupervised Learning
given input data without any additional feedback, learn patterns

Clustering
organizing a set of objects into groups in such a way that similar objects tend to be in the same group

k-means clustering
algorithm for clustering data based on repeatedly assigning points to clusters and updating those clusters' center





